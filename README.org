* Machine Learning
** KNN
*** 一般流程
1. 收集数据
2. 准备数据
3. 分析数据
4. 测试算法
5. 使用算法

*** python步骤
1. 创建KNN.py
2. 计算已知类别数据集中的点与当前点之间的距离
3. 按照距离递增次序排序
4. 选取与当前点距离最小的k个点
5. 确定前k个点所在类别的出现频率
6. 返回前k个点出现频率最高的类别作为当前点的预测分类.
*** 示例2 约会网站的分类
- 数据特征
|每年获得的飞行常客里程数|玩视频游戏所耗时时间百分比|每周消费的冰激凌公升数|

- 创建file2matrix函数
#+BEGIN_SRC python
  def file2matrix(filename):
      fr = open(filename)
      arrayOlines = fr.readlines()
      # 文件行数
      numberOfLines = len(arrayOlines)
      # 创建以0填充的矩阵。
      returnMat = zeros((numberOfLines, 3))
      classLabelVector = []
      index = 0
      for line in arrayOlines:
          # 每行有4个数据
          line = line.strip()
          # 4数据组成的list
          listFromLine = line.split('\t')
          # 将数据转化为矩阵
          returnMat[index, :] = listFromLine[0:3]
          if listFromLine[-1] == 'didntLike':
              classLabelVector.append(1)
          elif listFromLine[-1] == 'smallDoses':
              classLabelVector.append(2)
          elif listFromLine[-1] == 'largeDoses':
              classLabelVector.append(3)
          index += 1
      return returnMat, classLabelVector

#+END_SRC
- 代码主要功能
将文本数据转化为矩阵数据，将特征值转变为矩阵里的数学值，并将‘不喜欢’，‘一点喜欢’， ‘非常喜欢’转变未1-3的数字。
返回 训练样本矩阵和类标签向量。
- 归一化数值
#+BEGIN_SRC python
  #newvalue = (oldvalue-min)/(max-min)
  def autoNorm(dataSet):
      minVals = dataSet.min(0)
      maxVals = dataSet.max(0)
      ranges = maxVals - minVals
      normDataSet = zeros(shape(dataSet))
      m = dataSet.shape[0]
      normDataSet = dataSet - tile(minVals, (m, 1))
      normDataSet = normDataSet/tile(ranges, (m, 1))
      return normDataSet, ranges, minVals
#+END_SRC
  代码功能，将矩阵数据转换为0-1之间的数据。
- 测试算法
取已提供数据的90%作为训练样本集，而其余的10%数据去测试分类器，检测分类器的正确率。
#+BEGIN_SRC python
  def datingClassTest():
      hoRatio = 0.05
      datingDataMat, datingLabels = file2matrix('datingTestSet.txt')
      normMat, ranges, minVals = autoNorm(datingDataMat)
      m = normMat.shape[0]
      numTestVecs = int(m*hoRatio)
      errorCount = 0.0
      for i in range(numTestVecs):
          a = normMat[i,:]
          b = normMat[numTestVecs:m,:]
          c = datingLabels[numTestVecs:m]
          classifierResult = classify0(a, b, c, 3)
          print('the classifier came back with : %d, the real answer is : %d'%(classifierResult, datingLabels[i]))
          if (classifierResult != datingLabels[i]):
              errorCount += 1
              print('the total error rate is :%f'%(errorCount/float(numTestVecs)))

#+END_SRC


- 构建完整可用系统
** 决策树
*** 优缺点
- 计算复杂度不高,输出结果易于理解,中间值确实不敏感,可处理不相关特征的数据
- 可能会产生过度匹配问题
- 适用数据: 数值型和标称型
*** 需解决问题
1. 当前数据集上哪个特征在划分数据时起决定性作用.

*** 一般流程
1. 收集数据
2. 准备数据: 只适用于标称数据.数据必须离散化
3. 分析数据
4. 训练算法:构造树的数据结构
5. 测试算法: 使用经验树计算错误率.
6. 使用算法:
